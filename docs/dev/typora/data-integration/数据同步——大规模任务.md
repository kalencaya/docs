# 数据同步——大规模任务

针对单同步位点的同步任务，同步框架可以很好地处理调度任务，但是如果有多个同步位点呢？

在很多电商开放平台中注册自研应用后，店铺可以向自研应用授权，自研应用获取到授权 token 后可以同步授权店铺的订单等数据。

但是问题来了，在请求订单类数据时需要携带每个授权店铺对应的授权 token 才能拉取对应店铺数据，而无法使用自研应用相关的 key 去请求所有授权店铺的数据。

在处理同步位点的时候，就需要考虑如何跟踪每个店铺的同步位点，如何处理每个店铺的数据同步？

* 统一位点，统一调度运行。只有一个位点，代表所有店铺的同步位点，当同步位点推进时，所有店铺都已经同步过那个时间段的数据；一个调度任务，任务运行时，单线程或多线程处理所有店铺在这个时间位点的数据同步。
  * 优点在于处理简单。
  * 对异常处理不够友好，当某一环节发生异常时所有店铺都需要重新处理。
  * 数据热点问题。大部分店铺都可以在预期时间内完成自己店铺的数据同步，一些店铺的数据量会非常庞大，拖累整体运行速度。
  * 新加入的店铺，只能同步在授权加入的时间之后的数据，无法越过当前位点同步之前的数据。
  * 显而易见，数据同步及时性不高。
* 单独位点，统一调度运行。每个店铺都单独追踪自己的同步位点；一个调度任务，任务运行时，单线程或多线程地处理所有店铺的数据同步，每个店铺同步数据时读取自己的同步位点，同步完成后推进自己的同步位点。
  * 这种方式，主要是弥补无法同步整体位点之前数据的缺陷。比如订单类接口，大部分电商平台只支持同步 90 天之内的数据，当授权后需要同步近 90 天内的数据，而不只是授权时间之后的数据。
* 单独位点，单独调度。为每个店铺建立一个调度任务，每个店铺的数据同步单独维护同步位点，单独调度。
  * 这种方式将每个店铺的数据同步作为一个单独的调度任务，首先不存在店铺间的数据热点问题，数据量少和数据量多的店铺都能获得较好的数据同步实时性体验。
  * 处理也简单。每个店铺作为一个调度任务，可以直接使用同步框架，无需额外的工作。
  * 缺点在于会引入大量的调度任务。

在实际的同步程序迭代过程中，上述三种方案在不同阶段、不同开发、不同应用中都有所涉及。这里介绍第三种方案实践过程中遇到的问题和解决方式。

## 任务创建

在实际的业务中，同步某平台店铺数量在 1000+以上，每日新增 2 ~ 7 家授权店铺，每月新增授权店铺过百。

当需要同步大量店铺时，调度的任务创建便不能简单地在调度系统后台人工创建，需要与授权流程打通通过任务模板自动创建调度任务。

公司选用 `xxl-job` 作为同步程序的调度系统，xxl-job 并没有提供相关的 open api 供企业进行系统集成。

通过内部 fork 出 2.2.0 版本的代码开发维护公司内部版本，暴露出任务创建、修改、启动、停止和删除功能接口，实现店铺授权、授权过期和取消授权后能够自动创建启动、暂停和删除任务等流程。

## 秒级任务

数据同步任务在有实时性要求的情况下，任务的调度频率为秒级。

xxl-job 核心设计目标时开发迅速、学习简单、轻量级、易扩展。

* 全异步化设计：调度中心异步触发远程执行器运行业务逻辑。
  * 异步调度：调度中心有 2 个线程池用于处理不同频率的调度任务触发，调度中心每次任务触发时仅发送一次调度请求，执行器接收到触发调度请求后推入调度队列，调度中心调度请求也随之结束。
  * 异步执行：每个调度任务由一个异步线程和调度队列组成，任务线程不断从调度队列中获取任务异步执行业务逻辑。
  * 异步回调执行结果：当任务执行结束后会将执行结果推入回调队列，由回调线程批量将任务结果发送给调度中心。
* 轻量级设计：job 逻辑非常“轻”，在全异步化的基础上，单个 job 运行平均耗时基本在 “10ms” 之内（基本为一次请求的网络开销），因此，可以保证使用有限的线程支撑大量的JOB并发运行。

得益于上述两点优化，理论上默认配置下的调度中心，单机能够支撑 5000 任务并发运行稳定运行。

这里的单机支撑 5000 任务是以分钟、小时或天级的时候能很好地运行，但如果单机全为秒级任务，那么情况就会急剧恶化。

* 有高可用而无负载。xxl-job 的分布式调度中心只支持高可用，而无法实现调度任务在集群内负载。调度中心在调度任务时集群实例需要竞争分布式锁后扫表进行任务调度，因此同一时刻集群内只有一个实例在处理调度任务，当调度任务以分钟、小时或天级为主时可以支撑大量任务运行，如果是以秒级为主，很考验单机能力。
* 调度线程池打满。在秒级任务超过 500 时，200 线程的调度线程池出现被打满的情况。
* 调度中心和执行器通信超时。调度中心和执行器以 http 协议通信，xxl-job 在执行器拉起一个基于 netty 的 http 服务器接收调度中心请求。调度中心主动请求执行器和执行器主动请求调度中心都是临时创建一个连接，用完销毁，在大量秒级任务情况下开始出现通信超时情况。

### 调度日志

xxl-job 提供日志白屏化功能，可以在调度中心后台查看任务调度日志。任务执行过程中，业务代码也可以像调度日志中输出业务日志，并在调度中心后台查看。

任务日志分为 2 部分：调度中心任务日志记录和执行器任务日志文件。

* 任务日志记录。存储在调度中心数据库中。
* 任务日志文件。存在在执行器磁盘中，以日志文件形式存在。

秒级调度任务每天会产生大量任务调度日志，过千的秒级任务会每天产生数千万甚至上亿的任务调度日志，给数据库和执行器磁盘造成很大的压力。

xxl-job 的日志白屏化功能会在执行器服务器打印任务调度运行日志，每次调度都会创建一个日志文件，不仅占据大量磁盘空间，更甚至在磁盘空间满之前耗尽服务器 inodes。

### 日志清理

xxl-job 提供了日志清理功能，包括调度中心后台的手动清理和调度中心、执行器的自动清理。

任务分为 2 部分，日志的清理也是单独进行的，当调度中心清理数据库任务日志时，并不会同步或异步删除执行器日志文件。

调度中心和执行器都可以配置日志保留天数。因为执行器的任务日志文件是以天为单位来存储的，可能这也是日志保留时间以天为单元的原因。

调度中心最少可以保留 7 天，执行器最少可以保留 3 天。

## 线程资源

大量的调度任务存在不仅是对调度系统造成了很大的压力，暴露出很多问题，数据同步程序也同样出现很多状况。

最明显的变化在于服务器 CPU 的飙升。

CPU 的随着调度任务的增多而飙升属于正常现象。在 grafana 中展示的服务器 CPU 信息为通过 prometheus 收集的 spring-boot-actuator 的监控信息，CPU 使用率评估的是 CPU 的空闲情况，当有大量调度任务运行在数据同步程序上时，CPU 会更多地执行任务，CPU 使用率上升属于合理的自然情况。

同理的还有服务器负载上升。

而数据同步程序暴露出来的需要亟需改善的问题在于线程数的增多。

在以调度任务为单位进行线程分配的地方都会受到大量调度任务增加带来的影响。

* 调度系统创建的调度线程。xxl-job 在执行器为每个任务分配一个调度队列和调度线程用于任务的下发和执行。当有大量调度任务运行在一个执行器上时会创建大量的任务线程用于任务执行。xxl-job 不会一直维护任务线程的存活，多次从调度队列获取任务失败后会自动销毁，避免执行器出现过多的任务线程。但是秒级任务场景下任务线程会一直存在。
* 数据持久化线程。数据同步程序的核心流程为单线程同步拉取某个时间范围的数据，多线程异步持久化。为每个调度任务分配一定量的持久化线程也是造成线程数大幅增加的原因。

